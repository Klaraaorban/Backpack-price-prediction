{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Compartments</th>\n",
       "      <th>Weight Capacity (kg)</th>\n",
       "      <th>Price</th>\n",
       "      <th>Brand_Adidas</th>\n",
       "      <th>Brand_Jansport</th>\n",
       "      <th>Brand_Nike</th>\n",
       "      <th>Brand_Puma</th>\n",
       "      <th>Brand_Under Armour</th>\n",
       "      <th>Brand_nan</th>\n",
       "      <th>Material_Canvas</th>\n",
       "      <th>...</th>\n",
       "      <th>Style_Messenger</th>\n",
       "      <th>Style_Tote</th>\n",
       "      <th>Style_nan</th>\n",
       "      <th>Color_Black</th>\n",
       "      <th>Color_Blue</th>\n",
       "      <th>Color_Gray</th>\n",
       "      <th>Color_Green</th>\n",
       "      <th>Color_Pink</th>\n",
       "      <th>Color_Red</th>\n",
       "      <th>Color_nan</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>13.340058</td>\n",
       "      <td>143.445135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.918030</td>\n",
       "      <td>72.086319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>24.088386</td>\n",
       "      <td>29.699631</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>27.181990</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>11.258172</td>\n",
       "      <td>71.953236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Compartments  Weight Capacity (kg)       Price  Brand_Adidas  \\\n",
       "0           2.0             13.340058  143.445135           0.0   \n",
       "1           4.0              5.918030   72.086319           0.0   \n",
       "2           5.0             24.088386   29.699631           0.0   \n",
       "3           1.0              5.000000   27.181990           0.0   \n",
       "4           8.0             11.258172   71.953236           0.0   \n",
       "\n",
       "   Brand_Jansport  Brand_Nike  Brand_Puma  Brand_Under Armour  Brand_nan  \\\n",
       "0             1.0         0.0         0.0                 0.0        0.0   \n",
       "1             0.0         0.0         0.0                 1.0        0.0   \n",
       "2             0.0         1.0         0.0                 0.0        0.0   \n",
       "3             0.0         1.0         0.0                 0.0        0.0   \n",
       "4             0.0         0.0         0.0                 1.0        0.0   \n",
       "\n",
       "   Material_Canvas  ...  Style_Messenger  Style_Tote  Style_nan  Color_Black  \\\n",
       "0              0.0  ...              0.0         0.0        0.0          0.0   \n",
       "1              0.0  ...              0.0         1.0        0.0          0.0   \n",
       "2              0.0  ...              1.0         0.0        0.0          0.0   \n",
       "3              0.0  ...              1.0         0.0        0.0          0.0   \n",
       "4              0.0  ...              0.0         0.0        1.0          1.0   \n",
       "\n",
       "   Color_Blue  Color_Gray  Color_Green  Color_Pink  Color_Red  Color_nan  \n",
       "0         0.0         0.0          1.0         0.0        0.0        0.0  \n",
       "1         0.0         0.0          0.0         1.0        0.0        0.0  \n",
       "2         0.0         0.0          0.0         0.0        1.0        0.0  \n",
       "3         0.0         0.0          0.0         1.0        0.0        0.0  \n",
       "4         0.0         0.0          0.0         0.0        0.0        0.0  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "train = pd.read_csv(\"dataset.csv\")\n",
    "train['Compartments'] = train['Compartments'].fillna(train['Compartments'].median())\n",
    "features = ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_category = encoder.fit_transform(train[features])\n",
    "encoded_df = pd.DataFrame(encoded_category, columns=encoder.get_feature_names_out(features))\n",
    "\n",
    "train = train.drop(columns=features).reset_index(drop=True)\n",
    "train = pd.concat([train, encoded_df], axis=1)\n",
    "train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 1594.5033143876117\n",
      "Mean Absolute Error: 34.25700570938816\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "train = train.dropna(subset=['Price'])\n",
    "\n",
    "X = train.drop(columns=['Price'])\n",
    "y = train['Price']\n",
    "\n",
    "X_encoded = pd.get_dummies(X, drop_first=True)\n",
    "\n",
    "xtr, xte, ytr, yte = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(xtr, ytr)\n",
    "\n",
    "y_pred = model.predict(xte)\n",
    "\n",
    "mse = mean_squared_error(yte, y_pred)\n",
    "mae = mean_absolute_error(yte, y_pred)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [73.96882  78.78145  83.007385 83.53759  88.74695  74.53537  87.04291\n",
      " 88.052536 66.94466  78.603455 79.02738  85.2419   85.2352   78.70987\n",
      " 81.89919  95.88264  79.350006 69.07209  82.74044  83.09205  80.608635\n",
      " 84.01324  83.676735 79.836365 78.0928   76.281204 64.59686  80.55926\n",
      " 83.546364 82.939415 80.40112  84.30337  95.338806 70.96474  81.09933\n",
      " 80.19031  89.70524  79.36484  77.47422  83.16909  81.055115 75.914314\n",
      " 80.65211  76.702835 83.10643  89.873604 77.19324  59.14771  77.48837\n",
      " 85.7964  ]\n",
      "Mean Squared Error: 1568.0025634438039\n",
      "Mean Absolute Error: 34.18342997882912\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "train = pd.read_csv(\"dataset.csv\")\n",
    "\n",
    "train['Compartments'] = train['Compartments'].fillna(train['Compartments'].median())\n",
    "\n",
    "train['Total_Compartments'] = train['Compartments'] + train['Laptop Compartment'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "categorical_features = ['Brand', 'Material', 'Size', 'Laptop Compartment', 'Waterproof', 'Style', 'Color']\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_category = encoder.fit_transform(train[categorical_features])\n",
    "encoded_df = pd.DataFrame(encoded_category, columns=encoder.get_feature_names_out(categorical_features))\n",
    "\n",
    "train = train.drop(columns=categorical_features).reset_index(drop=True)\n",
    "train = pd.concat([train, encoded_df], axis=1)\n",
    "\n",
    "train = train.dropna(subset=['Price'])\n",
    "\n",
    "X = train.drop(columns=['Price'])\n",
    "y = train['Price']\n",
    "\n",
    "xtr, xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = XGBRegressor(n_estimators=500, learning_rate=0.05, max_depth=5, random_state=42)\n",
    "model.fit(xtr, ytr)\n",
    "\n",
    "y_pred = model.predict(xte)\n",
    "\n",
    "mse = mean_squared_error(yte, y_pred)\n",
    "mae = mean_absolute_error(yte, y_pred)\n",
    "\n",
    "print(f\"Prediction: {y_pred[:50]}\")\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "\n",
    "# feature_importances = pd.Series(model.feature_importances_, index=X_train.columns)\n",
    "# feature_importances.nlargest(10).plot(kind='barh')\n",
    "# plt.title(\"Top 10 Feature Importances\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "extra_df = pd.read_csv(\"training_extra.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# train_df.head()\n",
    "# extra_df.head()\n",
    "# test_df.head()\n",
    "\n",
    "def missing_values(df):\n",
    "    if df.isnull().sum().sum() > 0:\n",
    "        print(df.isnull().sum())\n",
    "    else:\n",
    "        print(\"No missing values\")\n",
    "\n",
    "# missing_values(train_df)\n",
    "# missing_values(extra_df)\n",
    "# missing_values(test_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obs:  3994318\n",
      "Features:  11\n"
     ]
    }
   ],
   "source": [
    "train = pd.concat([train_df, extra_df])\n",
    "\n",
    "print(f\"Obs: \", train.shape[0])\n",
    "print(f\"Features: \" ,train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Brand                   126758\n",
      "Material                110962\n",
      "Size                     87785\n",
      "Compartments                 0\n",
      "Laptop Compartment       98533\n",
      "Waterproof               94324\n",
      "Style                   104180\n",
      "Color                   133617\n",
      "Weight Capacity (kg)      1808\n",
      "Price                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train.drop('id', axis=1, inplace=True)\n",
    "train.drop_duplicates(inplace=True)\n",
    "missing_values(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dellg3\\AppData\\Local\\Temp\\ipykernel_1792\\1988700730.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  train_df['Weight Capacity (kg)'].fillna(train_df['Weight Capacity (kg)'].median(), inplace=True)\n",
      "C:\\Users\\dellg3\\AppData\\Local\\Temp\\ipykernel_1792\\1988700730.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_df['Weight Capacity (kg)'].fillna(test_df['Weight Capacity (kg)'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_df['Weight Capacity (kg)'].fillna(train_df['Weight Capacity (kg)'].median(), inplace=True)\n",
    "test_df['Weight Capacity (kg)'].fillna(test_df['Weight Capacity (kg)'].median(), inplace=True)\n",
    "# missing_values(train_df)\n",
    "# missing_values(test_df)\n",
    "train_df.fillna('Unknown', inplace=True)\n",
    "test_df.fillna('Unknown', inplace=True)\n",
    "# missing_values(train_df)\n",
    "# missing_values(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  81.36217459275402\n",
      "Median:  80.98495\n",
      "Standard Deviation:  38.93868410784115\n",
      "Minimum:  15.0\n",
      "Maximum:  150.0\n",
      "Change in Price:  135.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mean: \", train['Price'].mean())\n",
    "print(f\"Median: \", train['Price'].median())\n",
    "print(f\"Standard Deviation: \", train['Price'].std())\n",
    "print(f\"Minimum: \", train['Price'].min())\n",
    "print(f\"Maximum: \", train['Price'].max())\n",
    "print(f\"Change in Price: \", train['Price'].max() - train['Price'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Brand      Price   Count\n",
      "0  Under Armour  82.065208  801035\n",
      "1      Jansport  81.777549  749340\n",
      "2          Nike  81.284804  764407\n",
      "3          Puma  81.225577  755778\n",
      "4        Adidas  80.527683  797000\n"
     ]
    }
   ],
   "source": [
    "brand_price = train.groupby('Brand')['Price'].mean().sort_values(ascending=False).reset_index()\n",
    "brand_count = train['Brand'].value_counts().reset_index()\n",
    "brand_count.columns = ['Brand', 'Count']\n",
    "brand_stats = pd.merge(brand_price, brand_count, on='Brand')\n",
    "print(brand_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Compartments      Price   Count\n",
      "0           8.0  81.730636  383172\n",
      "1           6.0  81.642001  360640\n",
      "2           2.0  81.616355  408150\n",
      "3           7.0  81.601284  400824\n",
      "4           4.0  81.573869  417246\n",
      "5          10.0  81.552311  396303\n",
      "6           5.0  81.474432  399418\n",
      "7           3.0  81.166371  406796\n",
      "8           1.0  81.032016  423577\n",
      "9           9.0  80.280526  398192\n"
     ]
    }
   ],
   "source": [
    "compartment_price = train.groupby('Compartments')['Price'].mean().sort_values(ascending=False).reset_index()\n",
    "compartment_count = train['Compartments'].value_counts().reset_index()\n",
    "compartment_count.columns = ['Compartments', 'Count']\n",
    "compartment_stats = pd.merge(compartment_price, compartment_count, on='Compartments')\n",
    "print(compartment_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Material      Price    Count\n",
      "0  Polyester  82.029424  1060882\n",
      "1     Canvas  81.831022   903632\n",
      "2      Nylon  81.071794   942656\n",
      "3    Leather  80.488749   976186\n"
     ]
    }
   ],
   "source": [
    "material_price = train.groupby('Material')['Price'].mean().sort_values(ascending=False).reset_index()\n",
    "material_count = train['Material'].value_counts().reset_index()\n",
    "material_count.columns = ['Material', 'Count']\n",
    "material_stats = pd.merge(material_price, material_count, on='Material')\n",
    "print(material_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Size      Price    Count\n",
      "0   Large  81.611747  1312295\n",
      "1   Small  81.467620  1239751\n",
      "2  Medium  81.201377  1354487\n"
     ]
    }
   ],
   "source": [
    "size_price = train.groupby('Size')['Price'].mean().sort_values(ascending=False).reset_index()\n",
    "size_count = train['Size'].value_counts().reset_index()\n",
    "size_count.columns = ['Size', 'Count']\n",
    "size_stats = pd.merge(size_price, size_count, on='Size')\n",
    "print(size_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Laptop Compartment      Price    Count\n",
      "0                Yes  81.420190  1972937\n",
      "1                 No  81.350487  1922848\n"
     ]
    }
   ],
   "source": [
    "laptop_compartment_price = train.groupby('Laptop Compartment')['Price'].mean().sort_values(ascending=False).reset_index()\n",
    "laptop_compartment_count = train['Laptop Compartment'].value_counts().reset_index()\n",
    "laptop_compartment_count.columns = ['Laptop Compartment', 'Count']\n",
    "laptop_compartment_stats = pd.merge(laptop_compartment_price, laptop_compartment_count, on='Laptop Compartment')\n",
    "print(laptop_compartment_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Waterproof      Price    Count\n",
      "0         No  81.438525  1930789\n",
      "1        Yes  81.411426  1969205\n"
     ]
    }
   ],
   "source": [
    "waterproof_price = train.groupby('Waterproof')['Price'].mean().sort_values(ascending=False).reset_index()\n",
    "waterproof_count = train['Waterproof'].value_counts().reset_index()\n",
    "waterproof_count.columns = ['Waterproof', 'Count']\n",
    "waterproof_stats = pd.merge(waterproof_price, waterproof_count, on='Waterproof')\n",
    "print(waterproof_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Style      Price    Count\n",
      "0       Tote  81.500007  1297942\n",
      "1   Backpack  81.357717  1262519\n",
      "2  Messenger  81.185531  1329677\n"
     ]
    }
   ],
   "source": [
    "style_price = train.groupby('Style')['Price'].mean().sort_values(ascending=False).reset_index()\n",
    "style_count = train['Style'].value_counts().reset_index()\n",
    "style_count.columns = ['Style', 'Count']\n",
    "style_stats = pd.merge(style_price, style_count, on='Style')\n",
    "print(style_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color      Price   Count\n",
      "0  Green  82.252359  617024\n",
      "1   Blue  82.013390  638485\n",
      "2   Pink  81.596170  688257\n",
      "3    Red  81.010017  630215\n",
      "4   Gray  80.917014  666110\n",
      "5  Black  80.326088  620610\n"
     ]
    }
   ],
   "source": [
    "color_price = train.groupby('Color')['Price'].mean().sort_values(ascending=False).reset_index()\n",
    "color_count = train['Color'].value_counts().reset_index()\n",
    "color_count.columns = ['Color', 'Count']\n",
    "color_stats = pd.merge(color_price, color_count, on='Color')\n",
    "print(color_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Weight Capacity (kg)  Price  Count\n",
      "0                   27.254424  150.0      1\n",
      "1                   27.254325  150.0      1\n",
      "2                   27.254061  150.0      1\n",
      "3                   27.253784  150.0      1\n",
      "4                   27.255874  150.0      1\n",
      "...                       ...    ...    ...\n",
      "1920340             24.252448   15.0      1\n",
      "1920341             22.572746   15.0      1\n",
      "1920342             16.886079   15.0      1\n",
      "1920343             27.572624   15.0      1\n",
      "1920344             13.205776   15.0      1\n",
      "\n",
      "[1920345 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "weight_capacity_price = train.groupby('Weight Capacity (kg)')['Price'].mean().sort_values(ascending=False).reset_index()\n",
    "weight_capacity_count = train['Weight Capacity (kg)'].value_counts().reset_index()\n",
    "weight_capacity_count.columns = ['Weight Capacity (kg)', 'Count']\n",
    "weight_capacity_stats = pd.merge(weight_capacity_price, weight_capacity_count, on='Weight Capacity (kg)')\n",
    "print(weight_capacity_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you look into the data you will see that the specifics dont make alone too big of a cange, this means, that the specifications together make the price change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.get_dummies(train_df, drop_first=True)\n",
    "test_df = pd.get_dummies(test_df, drop_first=True)\n",
    "# train_df.head() \n",
    "# test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = train_df.drop('Price', axis=1)\n",
    "y = train_df['Price']\n",
    "X_train, X_val, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_train_scaler = scaler.fit_transform(X_train)\n",
    "x_val_scaler = scaler.transform(X_val)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "def model_evaluation(model):\n",
    "    model.fit(x_train_scaler, y_train)\n",
    "    y_pred = model.predict(x_train_scaler)\n",
    "    y_value_pred = model.predict(x_val_scaler)\n",
    "    mse = mean_squared_error(y_train, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_train, y_pred))\n",
    "    mae = mean_absolute_error(y_train, y_pred)\n",
    "    r2 = r2_score(y_train, y_pred)\n",
    "\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "    print(f\"Root Mean Squared Error: {rmse}\")\n",
    "    print(f\"Mean Absolute Error: {mae}\")\n",
    "    print(f\"R2 Score: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.0\n",
      "Root Mean Squared Error: 0.0\n",
      "Mean Absolute Error: 0.0\n",
      "R2 Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "decision_tree = DecisionTreeRegressor()\n",
    "model_evaluation(decision_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Mean Squared Error: 1515.1187617\n",
      "Decision Tree Root Mean Squared Error: 38.9245265\n",
      "Decision Tree Mean Absolute Error: 33.6478037\n",
      "Decision Tree R² Score: 0.0009872\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Separate input (X) and target variable (y)\n",
    "X = train_df.drop('Price', axis=1)\n",
    "y = train_df['Price']\n",
    "\n",
    "# Ensure a proper train-test split (before scaling)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features properly\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)  # Fit on training data\n",
    "X_test_s = scaler.transform(X_test)  # Transform test data only\n",
    "\n",
    "# Model evaluation function\n",
    "def model_evaluation(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)  # Train model\n",
    "    y_pred = model.predict(X_test)  # Predictions\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    return mse, rmse, mae, r2\n",
    "\n",
    "# Train Decision Tree with constraints to prevent overfitting\n",
    "decision_tree = DecisionTreeRegressor(max_depth=5, min_samples_split=10, random_state=42)\n",
    "dt_mse, dt_rmse, dt_mae, dt_r2 = model_evaluation(decision_tree, X_train_s, y_train, X_test_s, y_test)\n",
    "\n",
    "# Print results with more decimal places\n",
    "print(f\"Decision Tree Mean Squared Error: {dt_mse:.7f}\")\n",
    "print(f\"Decision Tree Root Mean Squared Error: {dt_rmse:.7f}\")\n",
    "print(f\"Decision Tree Mean Absolute Error: {dt_mae:.7f}\")\n",
    "print(f\"Decision Tree R² Score: {dt_r2:.7f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
